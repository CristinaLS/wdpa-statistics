import arcpy
import os
import time
from arcpy import env

#start the stopwatch
start = time.clock()

# enable the overwriting of outputs
arcpy.env.overwriteOutput = True

# define workspace to house all outputs from the script we want to keep
arcpy.env.workspace = "C:\Users\EdwardL\Documents\ArcGIS\Default.gdb"
workspace = env.workspace

# define the scratch workspace for outputs we dont want to keep
arcpy.env.scratchWorkspace = "C:\Users\EdwardL\Documents\ArcGIS\Modelbuilder_Primary.gdb"

# define the projection files used to define outputs/workspaces
in_mollweideprj = "C:\Users\EdwardL\Desktop\Temp_Files Of_Interest\moll_projection.prj"

# create the feature datasets in your workspace to help structure your outputs
# for initial outputs
in_fd1 = arcpy.CreateFeatureDataset_management(workspace,"a_merged_inputs")
# for outputs from the Union tool
in_fd2 = arcpy.CreateFeatureDataset_management(workspace,"b_processed_inputs")
# for outputs in the Mollweide projection
in_fd2 = arcpy.CreateFeatureDataset_management(workspace,"c_area_outputs", in_mollweideprj)
# for national outputs
in_fd3 = arcpy.CreateFeatureDataset_management(workspace,"d_national_outputs")
# for PAME national outputs
in_fd4 = arcpy.CreateFeatureDataset_management(workspace,"e_national_pame_outputs")


# define the scripts inputs
# WDPA Public points
in_points = r"E:\_Useful_Datasets_\Model_test_country\CHL_Test.gdb\CHL_Test_Pnt"
# WDPA Public polygons
in_polygons = r"E:\_Useful_Datasets_\Model_test_country\BLM_model_testing.gdb\BLM_model_testing_subset"
# Basemap_spatial
in_basemap_spat = r"E:\_Useful_Datasets_\WVS_Jan_16\SDG_Basemap.gdb\EEZv8_WVS_DIS_V3_ALL_final_v7dis_with_SDG_regions_for_models"
# Basemap_tabular
in_basemap_tab = r"E:\_Useful_Datasets_\WVS_Jan_16\SDG_Basemap.gdb\EEZv8_WVS_DIS_V3_ALL_final_v7dis_with_SDG_regions_for_models_tabular"
# PAME sites
in_pame_sites = r"C:\Users\EdwardL\Documents\ArcGIS\Restricted_Data.gdb\PAME_Sites"

# define the scripts restricted inputs - only accessible for UNEP-WCMC
# restricted CHN points
in_restrict_chn_pnt = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\CHN_restricted_testing_for_model_pnt"
# restricted CHN polygons
in_restrict_chn_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\CHN_restricted_testing_for_model"
# restricted SHN polygons
in_restrict_shn_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\EST_restricted_testing_for_model"
# restricted EST polygons
in_restrict_est_poly = r"E:\_Useful_Datasets_\Model_test_country\Restricted_subset_model_testing.gdb\SHN_restricted_testing_for_model"

# define the merge outputs
out_all_points = "all_wdpa_points"
out_all_polygons = "all_wdpa_polygons"

#--------------------------------------------------------------------------------------------------------------------------
# Stage 1: Global analysis

print ("Stage 1/3: Global analysis")

# combine the point inputs together
arcpy.Merge_management([in_points,in_restrict_chn_pnt], out_all_points)
# combine the polygon inputs together
arcpy.Merge_management([in_polygons, in_restrict_chn_poly, in_restrict_shn_poly, in_restrict_est_poly], out_all_polygons)

# repair geometries for newly merged files
arcpy.RepairGeometry_management("all_wdpa_points","DELETE_NULL")
arcpy.RepairGeometry_management("all_wdpa_polygons","DELETE_NULL")

# remove the sites that have an uncertain status or have potentially very innacruate areas
arcpy.Select_analysis("all_wdpa_points", "in_memory\all_wdpa_points_select","STATUS in ( 'Adopted', 'Designated', 'Inscribed') AND NOT DESIG_ENG = 'UNESCO-MAB Biosphere Reserve'")
arcpy.Select_analysis("all_wdpa_polygons", "in_memory\all_wdpa_polygons_select","STATUS in ( 'Adopted', 'Designated', 'Inscribed') AND NOT DESIG_ENG = 'UNESCO-MAB Biosphere Reserve'")

# convert the point selection into a polygon by buffering by the REP_AREA
arcpy.AddField_management("all_wdpa_points_select","radius","DOUBLE")
arcpy.CalculateField_management("all_wdpa_points_select","radius","math.sqrt(!REP_AREA!/math.pi )*1000","PYTHON_9.3")
arcpy.Buffer_analysis("all_wdpa_points_select","in_memory\all_wdpa_points_select_buff","radius","","","","","GEODESIC")

# combine the poly selection with the buffered point selection
arcpy.Merge_management(["all_wdpa_points_select_buff","all_wdpa_polygons_select"],"all_wdpa_polybuffpnt")

# this output (hereafter 'polybuffpnt') represents the starting point for the monthly release - it is all the sites we include
# in the analysis in one file
# repair it
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt","DELETE_NULL")

# split up the polybuffpnt using the Union tool - this splits up the WDPA like a Venn diagram
arcpy.Union_analysis("all_wdpa_polybuffpnt","all_wdpa_polybuffpnt_union")

# repair the output of the union
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union","DELETE_NULL")

# add xy coordinates for each of the ~1 million segments
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_union","CENTROID")

# add a new field to concatenate the new x and y coordinate fields
arcpy.AddField_management("all_wdpa_polybuffpnt_union","XYco","TEXT")

# populate this new XYco field
arcpy.CalculateField_management("all_wdpa_polybuffpnt_union","XYco","!CENTROID_X! + !CENTROID_Y!","PYTHON_9.3")

# run a summary of the XYco field, showing how many instances there are of each XYyco, i.e. how many segments have
# exactly the same XYco, and by extension geometry.
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union","xyco_count",[["XYco","COUNT"]],"XYco")

# join the xyco summary table back to the spatial data by XYco - adding the XYco COUNT field to the spatial data
arcpy.AddJoin_management("all_wdpa_polybuffpnt_union","XYco","xyco_count","XYco","KEEP_ALL")

# select out all of the segments which only have 1 XYco, i.e. the novel geometries with no overlaps within the WDPA
arcpy.Select_analysis("all_wdpa_polybuffpnt_union","in_memory\all_wdpa_polybuffpnt_union_unique","COUNT_XYco = 1")

### JOIN NAMES HERE ARE CAUSING PROBLEMS - HOW TO GET AROUND THAT??
### DELETE SOME FIELDS?

# select out all of the segments which have >1 XYco, i.e. geometries which overlap within the WDPA
arcpy.Select_analysis("all_wdpa_polybuffpnt_union","in_memory\all_wdpa_polybuffpnt_union_duplicates","COUNT_XYco > 1")

# remove the overlaps within the duplicates
arcpy.Dissolve_management("all_wdpa_polybuffpnt_union_duplicates","in_memory\all_wdpa_polybuffpnt_union_duplicates_diss","xyco_count_XYco","all_wdpa_polybuffpnt_union_STATUS_YR MIN; all_wdpa_polybuffpnt_union_ISO3 FIRST")

# repair the flattened duplicates
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_duplicates_diss","DELETE_NULL")

# recombine the unique geometries with the flattened duplicates
arcpy.Merge_management(["all_wdpa_polybuffpnt_union_duplicates_diss", "all_wdpa_polybuffpnt_union_unique"], "all_wdpa_polybuffpnt_union_flat")

# repair the recombined layer
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat","DELETE_NULL")

# intersect it with the basemap
arcpy.Intersect_analysis(["all_wdpa_polybuffpnt_union_flat",in_basemap_spat],"all_wdpa_polybuffpnt_union_flat_intersect")

# repair it
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat_intersect","DELETE_NULL")

# project it into mollweide, an equal area projection
arcpy.Project_management("all_wdpa_polybuffpnt_union_flat_intersect","all_wdpa_polybuffpnt_union_flat_intersect_project",in_mollweideprj)

# repair it
arcpy.RepairGeometry_management("all_wdpa_polybuffpnt_union_flat_intersect_project","DELETE_NULL")

# add and calculate a new area field
arcpy.AddGeometryAttributes_management("all_wdpa_polybuffpnt_union_flat_intersect_project","AREA_GEODESIC","","SQUARE_KILOMETERS",in_mollweideprj)

# now we get into a whole reem of summary statistics that have to created and rejigged in quite a specific way
# for the explanation and underlying rationale for these decisions please see accompanying metadata.

# run summary statistics on the layer globally
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","global_summary_statistics_",[["AREA_GEO","SUM"]],"type")

# run some summary stats on the layer per year for timeseries figures
arcpy.Statistics_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","global_summary_statistics_temporal",[["AREA_GEO","SUM"]],["type","all_wdpa_polybuffpnt_union_STATUS_YR"])

# pivot this temporal summary table
arcpy.PivotTable_management("global_summary_statistics_temporal","all_wdpa_polybuffpnt_union_STATUS_YR","type","SUM_AREA_GEO","global_summary_statistics_temporal_pivot")

# repeat the last two steps just for ABNJ geometries
# select out just the rows with an ISO3 of 'ABNJ'
arcpy.Select_analysis("all_wdpa_polybuffpnt_union_flat_intersect_project","ABNJ_sites","all_wdpa_polybuffpnt_union_ISO3 = 'ABNJ'")

# run some summary stats on the ABNJ selection per year for timeseries figures
arcpy.Statistics_analysis("ABNJ_sites","abnj_global_summary_statistics_temporal",[["AREA_GEO","SUM"]],"all_wdpa_polybuffpnt_union_STATUS_YR")

# properly combining these output tables has to be done manually in excel.
# this only takes 5 minutes and allows the user to sense check what the model has created.
